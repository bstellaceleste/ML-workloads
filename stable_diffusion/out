STARTING TIMING RUN AT 2024-09-16 12:46:20 AM
:::MLLOG {"namespace": "", "time_ms": 1726447597408, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1726447604483, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1726447604511, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1726447604511, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1726447604511, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1726447604512, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1726447604512, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1726447604512, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1726447604512, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
Using base config ['./configs/train_32x08x02_raw_images.yaml']
:::MLLOG {"namespace": "", "time_ms": 1726447604515, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2959736725, "metadata": {"file": "main.py", "lineno": 450}}
Global seed set to 2959736725
Using ckpt_path = /checkpoints/sd/512-base-ema.ckpt
LatentDiffusion: Running in v-prediction mode
building MemoryEfficientAttnBlock with 512 in_channels...
Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
building MemoryEfficientAttnBlock with 512 in_channels...
ModelCheckpoint(save_last=True, save_top_k=-1, monitor=None) will duplicate the last checkpoint saved.
Using 16bit None Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1726447626629, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 6513144, "metadata": {"file": "main.py", "lineno": 613}}
:::MLLOG {"namespace": "", "time_ms": 1726447626630, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1726447626630, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1726447626630, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 16, "metadata": {"file": "main.py", "lineno": 633}}
Setting learning rate to 2.00e-06 = 1 (accumulate_grad_batches) * 8 (num_gpus) * 2 (local_batch_size) * 1.25e-07 (base_lr)
:::MLLOG {"namespace": "", "time_ms": 1726447626630, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
[rank: 0] Global seed set to 2959736725
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/8
:::MLLOG {"namespace": "", "time_ms": 1726447633068, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1726447633098, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1726447633098, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1726447633098, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1726447633099, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1726447633099, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1726447633099, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1726447633099, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1726447633102, "event_type": "POINT_IN_TIME", "key": "seed", "value": 4132164901, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 5] Global seed set to 4132164901
:::MLLOG {"namespace": "", "time_ms": 1726447633803, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1726447633838, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1726447633838, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1726447633838, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1726447633838, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1726447633838, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1726447633838, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1726447633838, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1726447633842, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2531694739, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 7] Global seed set to 2531694739
:::MLLOG {"namespace": "", "time_ms": 1726447633823, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1726447633860, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1726447633860, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1726447633860, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1726447633861, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1726447633861, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1726447633861, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1726447633861, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1726447633865, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3849226580, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 4] Global seed set to 3849226580
:::MLLOG {"namespace": "", "time_ms": 1726447633882, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1726447633916, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1726447633916, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1726447633916, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1726447633916, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1726447633917, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1726447633917, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1726447633917, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1726447633921, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3581155171, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 1] Global seed set to 3581155171
:::MLLOG {"namespace": "", "time_ms": 1726447633915, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1726447633915, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1726447633959, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1726447633959, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1726447633960, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1726447633960, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1726447633960, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1726447633960, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1726447633960, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1726447633960, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1726447633961, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1726447633961, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1726447633961, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1726447633961, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1726447633961, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1726447633961, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1726447633967, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1886119813, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 3] Global seed set to 1886119813
:::MLLOG {"namespace": "", "time_ms": 1726447633968, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1826979823, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 6] Global seed set to 1826979823
:::MLLOG {"namespace": "", "time_ms": 1726447633934, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1726447633996, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1726447633997, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1726447633997, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1726447633997, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1726447633998, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1726447633998, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1726447633998, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1726447634005, "event_type": "POINT_IN_TIME", "key": "seed", "value": 740804658, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 2] Global seed set to 740804658
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1726447656088, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 6513144, "metadata": {"file": "main.py", "lineno": 613}}
:::MLLOG {"namespace": "", "time_ms": 1726447656089, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1726447656089, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1726447656090, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 16, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1726447656090, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
[rank: 5] Global seed set to 4132164901
Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/8
Missing logger folder: /results/2024-09-16T00-47-13_train_32x08x02_raw_images/diff_tb
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1726447657555, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 6513144, "metadata": {"file": "main.py", "lineno": 613}}
:::MLLOG {"namespace": "", "time_ms": 1726447657556, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1726447657556, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1726447657556, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 16, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1726447657557, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
[rank: 7] Global seed set to 2531694739
Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/8
Missing logger folder: /results/2024-09-16T00-47-13_train_32x08x02_raw_images/diff_tb
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1726447659105, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 6513144, "metadata": {"file": "main.py", "lineno": 613}}
:::MLLOG {"namespace": "", "time_ms": 1726447659105, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1726447659106, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1726447659106, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 16, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1726447659107, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
[rank: 6] Global seed set to 1826979823
Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/8
Missing logger folder: /results/2024-09-16T00-47-13_train_32x08x02_raw_images/diff_tb
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1726447659869, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 6513144, "metadata": {"file": "main.py", "lineno": 613}}
:::MLLOG {"namespace": "", "time_ms": 1726447659870, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1726447659871, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1726447659872, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 16, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1726447659872, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
[rank: 1] Global seed set to 3581155171
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/8
Missing logger folder: /results/2024-09-16T00-47-13_train_32x08x02_raw_images/diff_tb
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1726447660828, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 6513144, "metadata": {"file": "main.py", "lineno": 613}}
:::MLLOG {"namespace": "", "time_ms": 1726447660828, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1726447660829, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1726447660829, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 16, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1726447660829, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
[rank: 2] Global seed set to 740804658
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/8
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1726447660887, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 6513144, "metadata": {"file": "main.py", "lineno": 613}}
:::MLLOG {"namespace": "", "time_ms": 1726447660887, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1726447660887, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1726447660888, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 16, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1726447660888, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1726447660889, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 6513144, "metadata": {"file": "main.py", "lineno": 613}}
[rank: 3] Global seed set to 1886119813
:::MLLOG {"namespace": "", "time_ms": 1726447660890, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1726447660890, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/8
:::MLLOG {"namespace": "", "time_ms": 1726447660891, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 16, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1726447660891, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
[rank: 4] Global seed set to 3849226580
Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/8
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 8 processes
----------------------------------------------------------------------------------------------------

Missing logger folder: /results/2024-09-16T00-46-44_train_32x08x02_raw_images/diff_tb
Missing logger folder: /results/2024-09-16T00-47-13_train_32x08x02_raw_images/diff_tb
Missing logger folder: /results/2024-09-16T00-47-13_train_32x08x02_raw_images/diff_tb
Missing logger folder: /results/2024-09-16T00-47-13_train_32x08x02_raw_images/diff_tb
Configure sharded model for LatentDiffusion
Deleting key model.diffusion_model.time_embed.0.weight from state_dict.
Deleting key model.diffusion_model.time_embed.0.bias from state_dict.
Deleting key model.diffusion_model.time_embed.2.weight from state_dict.
Deleting key model.diffusion_model.time_embed.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.0.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.0.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.3.0.op.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.3.0.op.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.6.0.op.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.6.0.op.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.9.0.op.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.9.0.op.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.norm.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.norm.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.1.conv.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.1.conv.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.2.conv.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.2.conv.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.2.conv.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.2.conv.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.out.0.weight from state_dict.
Deleting key model.diffusion_model.out.0.bias from state_dict.
Deleting key model.diffusion_model.out.2.weight from state_dict.
Deleting key model.diffusion_model.out.2.bias from state_dict.
Restored from /checkpoints/sd/512-base-ema.ckpt with 686 missing and 2 unexpected keys
Missing Keys:
 ['model.diffusion_model.time_embed.0.weight', 'model.diffusion_model.time_embed.0.bias', 'model.diffusion_model.time_embed.2.weight', 'model.diffusion_model.time_embed.2.bias', 'model.diffusion_model.input_blocks.0.0.weight', 'model.diffusion_model.input_blocks.0.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.1.1.norm.weight', 'model.diffusion_model.input_blocks.1.1.norm.bias', 'model.diffusion_model.input_blocks.1.1.proj_in.weight', 'model.diffusion_model.input_blocks.1.1.proj_in.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.1.1.proj_out.weight', 'model.diffusion_model.input_blocks.1.1.proj_out.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.2.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.2.1.norm.weight', 'model.diffusion_model.input_blocks.2.1.norm.bias', 'model.diffusion_model.input_blocks.2.1.proj_in.weight', 'model.diffusion_model.input_blocks.2.1.proj_in.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.2.1.proj_out.weight', 'model.diffusion_model.input_blocks.2.1.proj_out.bias', 'model.diffusion_model.input_blocks.3.0.op.weight', 'model.diffusion_model.input_blocks.3.0.op.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.4.0.skip_connection.weight', 'model.diffusion_model.input_blocks.4.0.skip_connection.bias', 'model.diffusion_model.input_blocks.4.1.norm.weight', 'model.diffusion_model.input_blocks.4.1.norm.bias', 'model.diffusion_model.input_blocks.4.1.proj_in.weight', 'model.diffusion_model.input_blocks.4.1.proj_in.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.4.1.proj_out.weight', 'model.diffusion_model.input_blocks.4.1.proj_out.bias', 'model.diffusion_model.input_blocks.5.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.5.1.norm.weight', 'model.diffusion_model.input_blocks.5.1.norm.bias', 'model.diffusion_model.input_blocks.5.1.proj_in.weight', 'model.diffusion_model.input_blocks.5.1.proj_in.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.5.1.proj_out.weight', 'model.diffusion_model.input_blocks.5.1.proj_out.bias', 'model.diffusion_model.input_blocks.6.0.op.weight', 'model.diffusion_model.input_blocks.6.0.op.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.7.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.7.0.skip_connection.weight', 'model.diffusion_model.input_blocks.7.0.skip_connection.bias', 'model.diffusion_model.input_blocks.7.1.norm.weight', 'model.diffusion_model.input_blocks.7.1.norm.bias', 'model.diffusion_model.input_blocks.7.1.proj_in.weight', 'model.diffusion_model.input_blocks.7.1.proj_in.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.7.1.proj_out.weight', 'model.diffusion_model.input_blocks.7.1.proj_out.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.8.1.norm.weight', 'model.diffusion_model.input_blocks.8.1.norm.bias', 'model.diffusion_model.input_blocks.8.1.proj_in.weight', 'model.diffusion_model.input_blocks.8.1.proj_in.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.8.1.proj_out.weight', 'model.diffusion_model.input_blocks.8.1.proj_out.bias', 'model.diffusion_model.input_blocks.9.0.op.weight', 'model.diffusion_model.input_blocks.9.0.op.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.3.bias', 'model.diffusion_model.middle_block.0.in_layers.0.weight', 'model.diffusion_model.middle_block.0.in_layers.0.bias', 'model.diffusion_model.middle_block.0.in_layers.2.weight', 'model.diffusion_model.middle_block.0.in_layers.2.bias', 'model.diffusion_model.middle_block.0.emb_layers.1.weight', 'model.diffusion_model.middle_block.0.emb_layers.1.bias', 'model.diffusion_model.middle_block.0.out_layers.0.weight', 'model.diffusion_model.middle_block.0.out_layers.0.bias', 'model.diffusion_model.middle_block.0.out_layers.3.weight', 'model.diffusion_model.middle_block.0.out_layers.3.bias', 'model.diffusion_model.middle_block.1.norm.weight', 'model.diffusion_model.middle_block.1.norm.bias', 'model.diffusion_model.middle_block.1.proj_in.weight', 'model.diffusion_model.middle_block.1.proj_in.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.middle_block.1.proj_out.weight', 'model.diffusion_model.middle_block.1.proj_out.bias', 'model.diffusion_model.middle_block.2.in_layers.0.weight', 'model.diffusion_model.middle_block.2.in_layers.0.bias', 'model.diffusion_model.middle_block.2.in_layers.2.weight', 'model.diffusion_model.middle_block.2.in_layers.2.bias', 'model.diffusion_model.middle_block.2.emb_layers.1.weight', 'model.diffusion_model.middle_block.2.emb_layers.1.bias', 'model.diffusion_model.middle_block.2.out_layers.0.weight', 'model.diffusion_model.middle_block.2.out_layers.0.bias', 'model.diffusion_model.middle_block.2.out_layers.3.weight', 'model.diffusion_model.middle_block.2.out_layers.3.bias', 'model.diffusion_model.output_blocks.0.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.0.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.0.0.skip_connection.weight', 'model.diffusion_model.output_blocks.0.0.skip_connection.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.1.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.1.0.skip_connection.weight', 'model.diffusion_model.output_blocks.1.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.2.0.skip_connection.weight', 'model.diffusion_model.output_blocks.2.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.1.conv.weight', 'model.diffusion_model.output_blocks.2.1.conv.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.3.0.skip_connection.weight', 'model.diffusion_model.output_blocks.3.0.skip_connection.bias', 'model.diffusion_model.output_blocks.3.1.norm.weight', 'model.diffusion_model.output_blocks.3.1.norm.bias', 'model.diffusion_model.output_blocks.3.1.proj_in.weight', 'model.diffusion_model.output_blocks.3.1.proj_in.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.3.1.proj_out.weight', 'model.diffusion_model.output_blocks.3.1.proj_out.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.4.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.4.0.skip_connection.weight', 'model.diffusion_model.output_blocks.4.0.skip_connection.bias', 'model.diffusion_model.output_blocks.4.1.norm.weight', 'model.diffusion_model.output_blocks.4.1.norm.bias', 'model.diffusion_model.output_blocks.4.1.proj_in.weight', 'model.diffusion_model.output_blocks.4.1.proj_in.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.4.1.proj_out.weight', 'model.diffusion_model.output_blocks.4.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.5.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.5.0.skip_connection.weight', 'model.diffusion_model.output_blocks.5.0.skip_connection.bias', 'model.diffusion_model.output_blocks.5.1.norm.weight', 'model.diffusion_model.output_blocks.5.1.norm.bias', 'model.diffusion_model.output_blocks.5.1.proj_in.weight', 'model.diffusion_model.output_blocks.5.1.proj_in.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.5.1.proj_out.weight', 'model.diffusion_model.output_blocks.5.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.2.conv.weight', 'model.diffusion_model.output_blocks.5.2.conv.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.6.0.skip_connection.weight', 'model.diffusion_model.output_blocks.6.0.skip_connection.bias', 'model.diffusion_model.output_blocks.6.1.norm.weight', 'model.diffusion_model.output_blocks.6.1.norm.bias', 'model.diffusion_model.output_blocks.6.1.proj_in.weight', 'model.diffusion_model.output_blocks.6.1.proj_in.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.6.1.proj_out.weight', 'model.diffusion_model.output_blocks.6.1.proj_out.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.7.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.7.0.skip_connection.weight', 'model.diffusion_model.output_blocks.7.0.skip_connection.bias', 'model.diffusion_model.output_blocks.7.1.norm.weight', 'model.diffusion_model.output_blocks.7.1.norm.bias', 'model.diffusion_model.output_blocks.7.1.proj_in.weight', 'model.diffusion_model.output_blocks.7.1.proj_in.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.7.1.proj_out.weight', 'model.diffusion_model.output_blocks.7.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.8.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.8.0.skip_connection.weight', 'model.diffusion_model.output_blocks.8.0.skip_connection.bias', 'model.diffusion_model.output_blocks.8.1.norm.weight', 'model.diffusion_model.output_blocks.8.1.norm.bias', 'model.diffusion_model.output_blocks.8.1.proj_in.weight', 'model.diffusion_model.output_blocks.8.1.proj_in.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.8.1.proj_out.weight', 'model.diffusion_model.output_blocks.8.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.2.conv.weight', 'model.diffusion_model.output_blocks.8.2.conv.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.9.0.skip_connection.weight', 'model.diffusion_model.output_blocks.9.0.skip_connection.bias', 'model.diffusion_model.output_blocks.9.1.norm.weight', 'model.diffusion_model.output_blocks.9.1.norm.bias', 'model.diffusion_model.output_blocks.9.1.proj_in.weight', 'model.diffusion_model.output_blocks.9.1.proj_in.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.9.1.proj_out.weight', 'model.diffusion_model.output_blocks.9.1.proj_out.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.10.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.10.0.skip_connection.weight', 'model.diffusion_model.output_blocks.10.0.skip_connection.bias', 'model.diffusion_model.output_blocks.10.1.norm.weight', 'model.diffusion_model.output_blocks.10.1.norm.bias', 'model.diffusion_model.output_blocks.10.1.proj_in.weight', 'model.diffusion_model.output_blocks.10.1.proj_in.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.10.1.proj_out.weight', 'model.diffusion_model.output_blocks.10.1.proj_out.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.11.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.11.0.skip_connection.weight', 'model.diffusion_model.output_blocks.11.0.skip_connection.bias', 'model.diffusion_model.output_blocks.11.1.norm.weight', 'model.diffusion_model.output_blocks.11.1.norm.bias', 'model.diffusion_model.output_blocks.11.1.proj_in.weight', 'model.diffusion_model.output_blocks.11.1.proj_in.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.11.1.proj_out.weight', 'model.diffusion_model.output_blocks.11.1.proj_out.bias', 'model.diffusion_model.out.0.weight', 'model.diffusion_model.out.0.bias', 'model.diffusion_model.out.2.weight', 'model.diffusion_model.out.2.bias']

Unexpected Keys:
 ['model_ema.decay', 'model_ema.num_updates']
building MemoryEfficientAttnBlock with 512 in_channels...
Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
building MemoryEfficientAttnBlock with 512 in_channels...
Deleting key model.diffusion_model.time_embed.0.weight from state_dict.
Deleting key model.diffusion_model.time_embed.0.bias from state_dict.
Deleting key model.diffusion_model.time_embed.2.weight from state_dict.
Deleting key model.diffusion_model.time_embed.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.0.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.0.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.3.0.op.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.3.0.op.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.6.0.op.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.6.0.op.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.9.0.op.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.9.0.op.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.norm.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.norm.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.1.conv.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.1.conv.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.2.conv.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.2.conv.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.2.conv.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.2.conv.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.out.0.weight from state_dict.
Deleting key model.diffusion_model.out.0.bias from state_dict.
Deleting key model.diffusion_model.out.2.weight from state_dict.
Deleting key model.diffusion_model.out.2.bias from state_dict.
Restored from /checkpoints/sd/512-base-ema.ckpt with 686 missing and 2 unexpected keys
Missing Keys:
 ['model.diffusion_model.time_embed.0.weight', 'model.diffusion_model.time_embed.0.bias', 'model.diffusion_model.time_embed.2.weight', 'model.diffusion_model.time_embed.2.bias', 'model.diffusion_model.input_blocks.0.0.weight', 'model.diffusion_model.input_blocks.0.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.1.1.norm.weight', 'model.diffusion_model.input_blocks.1.1.norm.bias', 'model.diffusion_model.input_blocks.1.1.proj_in.weight', 'model.diffusion_model.input_blocks.1.1.proj_in.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.1.1.proj_out.weight', 'model.diffusion_model.input_blocks.1.1.proj_out.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.2.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.2.1.norm.weight', 'model.diffusion_model.input_blocks.2.1.norm.bias', 'model.diffusion_model.input_blocks.2.1.proj_in.weight', 'model.diffusion_model.input_blocks.2.1.proj_in.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.2.1.proj_out.weight', 'model.diffusion_model.input_blocks.2.1.proj_out.bias', 'model.diffusion_model.input_blocks.3.0.op.weight', 'model.diffusion_model.input_blocks.3.0.op.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.4.0.skip_connection.weight', 'model.diffusion_model.input_blocks.4.0.skip_connection.bias', 'model.diffusion_model.input_blocks.4.1.norm.weight', 'model.diffusion_model.input_blocks.4.1.norm.bias', 'model.diffusion_model.input_blocks.4.1.proj_in.weight', 'model.diffusion_model.input_blocks.4.1.proj_in.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.4.1.proj_out.weight', 'model.diffusion_model.input_blocks.4.1.proj_out.bias', 'model.diffusion_model.input_blocks.5.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.5.1.norm.weight', 'model.diffusion_model.input_blocks.5.1.norm.bias', 'model.diffusion_model.input_blocks.5.1.proj_in.weight', 'model.diffusion_model.input_blocks.5.1.proj_in.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.5.1.proj_out.weight', 'model.diffusion_model.input_blocks.5.1.proj_out.bias', 'model.diffusion_model.input_blocks.6.0.op.weight', 'model.diffusion_model.input_blocks.6.0.op.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.7.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.7.0.skip_connection.weight', 'model.diffusion_model.input_blocks.7.0.skip_connection.bias', 'model.diffusion_model.input_blocks.7.1.norm.weight', 'model.diffusion_model.input_blocks.7.1.norm.bias', 'model.diffusion_model.input_blocks.7.1.proj_in.weight', 'model.diffusion_model.input_blocks.7.1.proj_in.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.7.1.proj_out.weight', 'model.diffusion_model.input_blocks.7.1.proj_out.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.8.1.norm.weight', 'model.diffusion_model.input_blocks.8.1.norm.bias', 'model.diffusion_model.input_blocks.8.1.proj_in.weight', 'model.diffusion_model.input_blocks.8.1.proj_in.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.8.1.proj_out.weight', 'model.diffusion_model.input_blocks.8.1.proj_out.bias', 'model.diffusion_model.input_blocks.9.0.op.weight', 'model.diffusion_model.input_blocks.9.0.op.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.3.bias', 'model.diffusion_model.middle_block.0.in_layers.0.weight', 'model.diffusion_model.middle_block.0.in_layers.0.bias', 'model.diffusion_model.middle_block.0.in_layers.2.weight', 'model.diffusion_model.middle_block.0.in_layers.2.bias', 'model.diffusion_model.middle_block.0.emb_layers.1.weight', 'model.diffusion_model.middle_block.0.emb_layers.1.bias', 'model.diffusion_model.middle_block.0.out_layers.0.weight', 'model.diffusion_model.middle_block.0.out_layers.0.bias', 'model.diffusion_model.middle_block.0.out_layers.3.weight', 'model.diffusion_model.middle_block.0.out_layers.3.bias', 'model.diffusion_model.middle_block.1.norm.weight', 'model.diffusion_model.middle_block.1.norm.bias', 'model.diffusion_model.middle_block.1.proj_in.weight', 'model.diffusion_model.middle_block.1.proj_in.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.middle_block.1.proj_out.weight', 'model.diffusion_model.middle_block.1.proj_out.bias', 'model.diffusion_model.middle_block.2.in_layers.0.weight', 'model.diffusion_model.middle_block.2.in_layers.0.bias', 'model.diffusion_model.middle_block.2.in_layers.2.weight', 'model.diffusion_model.middle_block.2.in_layers.2.bias', 'model.diffusion_model.middle_block.2.emb_layers.1.weight', 'model.diffusion_model.middle_block.2.emb_layers.1.bias', 'model.diffusion_model.middle_block.2.out_layers.0.weight', 'model.diffusion_model.middle_block.2.out_layers.0.bias', 'model.diffusion_model.middle_block.2.out_layers.3.weight', 'model.diffusion_model.middle_block.2.out_layers.3.bias', 'model.diffusion_model.output_blocks.0.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.0.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.0.0.skip_connection.weight', 'model.diffusion_model.output_blocks.0.0.skip_connection.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.1.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.1.0.skip_connection.weight', 'model.diffusion_model.output_blocks.1.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.2.0.skip_connection.weight', 'model.diffusion_model.output_blocks.2.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.1.conv.weight', 'model.diffusion_model.output_blocks.2.1.conv.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.3.0.skip_connection.weight', 'model.diffusion_model.output_blocks.3.0.skip_connection.bias', 'model.diffusion_model.output_blocks.3.1.norm.weight', 'model.diffusion_model.output_blocks.3.1.norm.bias', 'model.diffusion_model.output_blocks.3.1.proj_in.weight', 'model.diffusion_model.output_blocks.3.1.proj_in.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.3.1.proj_out.weight', 'model.diffusion_model.output_blocks.3.1.proj_out.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.4.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.4.0.skip_connection.weight', 'model.diffusion_model.output_blocks.4.0.skip_connection.bias', 'model.diffusion_model.output_blocks.4.1.norm.weight', 'model.diffusion_model.output_blocks.4.1.norm.bias', 'model.diffusion_model.output_blocks.4.1.proj_in.weight', 'model.diffusion_model.output_blocks.4.1.proj_in.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.4.1.proj_out.weight', 'model.diffusion_model.output_blocks.4.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.5.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.5.0.skip_connection.weight', 'model.diffusion_model.output_blocks.5.0.skip_connection.bias', 'model.diffusion_model.output_blocks.5.1.norm.weight', 'model.diffusion_model.output_blocks.5.1.norm.bias', 'model.diffusion_model.output_blocks.5.1.proj_in.weight', 'model.diffusion_model.output_blocks.5.1.proj_in.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.5.1.proj_out.weight', 'model.diffusion_model.output_blocks.5.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.2.conv.weight', 'model.diffusion_model.output_blocks.5.2.conv.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.6.0.skip_connection.weight', 'model.diffusion_model.output_blocks.6.0.skip_connection.bias', 'model.diffusion_model.output_blocks.6.1.norm.weight', 'model.diffusion_model.output_blocks.6.1.norm.bias', 'model.diffusion_model.output_blocks.6.1.proj_in.weight', 'model.diffusion_model.output_blocks.6.1.proj_in.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.6.1.proj_out.weight', 'model.diffusion_model.output_blocks.6.1.proj_out.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.7.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.7.0.skip_connection.weight', 'model.diffusion_model.output_blocks.7.0.skip_connection.bias', 'model.diffusion_model.output_blocks.7.1.norm.weight', 'model.diffusion_model.output_blocks.7.1.norm.bias', 'model.diffusion_model.output_blocks.7.1.proj_in.weight', 'model.diffusion_model.output_blocks.7.1.proj_in.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.7.1.proj_out.weight', 'model.diffusion_model.output_blocks.7.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.8.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.8.0.skip_connection.weight', 'model.diffusion_model.output_blocks.8.0.skip_connection.bias', 'model.diffusion_model.output_blocks.8.1.norm.weight', 'model.diffusion_model.output_blocks.8.1.norm.bias', 'model.diffusion_model.output_blocks.8.1.proj_in.weight', 'model.diffusion_model.output_blocks.8.1.proj_in.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.8.1.proj_out.weight', 'model.diffusion_model.output_blocks.8.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.2.conv.weight', 'model.diffusion_model.output_blocks.8.2.conv.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.9.0.skip_connection.weight', 'model.diffusion_model.output_blocks.9.0.skip_connection.bias', 'model.diffusion_model.output_blocks.9.1.norm.weight', 'model.diffusion_model.output_blocks.9.1.norm.bias', 'model.diffusion_model.output_blocks.9.1.proj_in.weight', 'model.diffusion_model.output_blocks.9.1.proj_in.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.9.1.proj_out.weight', 'model.diffusion_model.output_blocks.9.1.proj_out.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.10.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.10.0.skip_connection.weight', 'model.diffusion_model.output_blocks.10.0.skip_connection.bias', 'model.diffusion_model.output_blocks.10.1.norm.weight', 'model.diffusion_model.output_blocks.10.1.norm.bias', 'model.diffusion_model.output_blocks.10.1.proj_in.weight', 'model.diffusion_model.output_blocks.10.1.proj_in.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.10.1.proj_out.weight', 'model.diffusion_model.output_blocks.10.1.proj_out.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.11.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.11.0.skip_connection.weight', 'model.diffusion_model.output_blocks.11.0.skip_connection.bias', 'model.diffusion_model.output_blocks.11.1.norm.weight', 'model.diffusion_model.output_blocks.11.1.norm.bias', 'model.diffusion_model.output_blocks.11.1.proj_in.weight', 'model.diffusion_model.output_blocks.11.1.proj_in.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.11.1.proj_out.weight', 'model.diffusion_model.output_blocks.11.1.proj_out.bias', 'model.diffusion_model.out.0.weight', 'model.diffusion_model.out.0.bias', 'model.diffusion_model.out.2.weight', 'model.diffusion_model.out.2.bias']

Unexpected Keys:
 ['model_ema.decay', 'model_ema.num_updates']
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
:::MLLOG {"namespace": "", "time_ms": 1726447703811, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adamw", "metadata": {"file": "ldm/models/diffusion/ddpm.py", "lineno": 1639}}
:::MLLOG {"namespace": "", "time_ms": 1726447703867, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_1", "value": 0.9, "metadata": {"file": "ldm/models/diffusion/ddpm.py", "lineno": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1726447703867, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_2", "value": 0.999, "metadata": {"file": "ldm/models/diffusion/ddpm.py", "lineno": 1641}}
:::MLLOG {"namespace": "", "time_ms": 1726447703868, "event_type": "POINT_IN_TIME", "key": "opt_adamw_epsilon", "value": 1e-08, "metadata": {"file": "ldm/models/diffusion/ddpm.py", "lineno": 1642}}
:::MLLOG {"namespace": "", "time_ms": 1726447703868, "event_type": "POINT_IN_TIME", "key": "opt_adamw_weight_decay", "value": 0.01, "metadata": {"file": "ldm/models/diffusion/ddpm.py", "lineno": 1643}}
:::MLLOG {"namespace": "", "time_ms": 1726447703868, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 2e-06, "metadata": {"file": "ldm/models/diffusion/ddpm.py", "lineno": 1644}}
:::MLLOG {"namespace": "", "time_ms": 1726447703870, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 1000, "metadata": {"file": "ldm/models/diffusion/ddpm.py", "lineno": 1650}}
Setting up LambdaLR scheduler...
Project config
model:
  base_learning_rate: 1.25e-07
  target: ldm.models.diffusion.ddpm.LatentDiffusion
  params:
    parameterization: v
    linear_start: 0.00085
    linear_end: 0.012
    num_timesteps_cond: 1
    log_every_t: 200
    timesteps: 1000
    first_stage_key: jpg
    first_stage_type: images
    cond_stage_key: txt
    image_size: 64
    channels: 4
    cond_stage_trainable: false
    conditioning_key: crossattn
    monitor: steps
    scale_factor: 0.18215
    use_ema: false
    load_vae: true
    load_unet: false
    load_encoder: true
    validation_config:
      sampler: ddim
      steps: 50
      scale: 8.0
      ddim_eta: 0.0
      prompt_key: caption
      image_fname_key: image_id
      save_images:
        enabled: false
        base_output_dir: /results/inference
      fid:
        enabled: true
        inception_weights_url: https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth
        cache_dir: /checkpoints/inception
        gt_path: /datasets/coco2014/val2014_30k_stats.npz
      clip:
        enabled: true
        clip_version: ViT-H-14
        cache_dir: /checkpoints/clip
    scheduler_config:
      target: ldm.lr_scheduler.LambdaLinearScheduler
      params:
        warm_up_steps:
        - 1000
        cycle_lengths:
        - 10000000000000
        f_start:
        - 1.0e-06
        f_max:
        - 1.0
        f_min:
        - 1.0
    unet_config:
      target: ldm.modules.diffusionmodules.openaimodel.UNetModel
      params:
        use_checkpoint: false
        use_fp16: true
        image_size: 32
        in_channels: 4
        out_channels: 4
        model_channels: 320
        attention_resolutions:
        - 4
        - 2
        - 1
        num_res_blocks: 2
        channel_mult:
        - 1
        - 2
        - 4
        - 4
        num_head_channels: 64
        use_spatial_transformer: true
        use_linear_in_transformer: true
        transformer_depth: 1
        context_dim: 1024
        legacy: false
    first_stage_config:
      target: ldm.models.autoencoder.AutoencoderKL
      params:
        embed_dim: 4
        monitor: val/rec_loss
        ddconfig:
          double_z: true
          z_channels: 4
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult:
          - 1
          - 2
          - 4
          - 4
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity
    cond_stage_config:
      target: ldm.modules.encoders.modules.FrozenOpenCLIPEmbedder
      params:
        arch: ViT-H-14
        version: laion2b_s32b_b79k
        freeze: true
        layer: penultimate
        cache_dir: /checkpoints/clip
    use_fp16: true
    ckpt: /checkpoints/sd/512-base-ema.ckpt
data:
  target: ldm.data.composable_data_module.ComposableDataModule
  params:
    train:
      target: ldm.data.webdatasets.build_dataloader
      params:
        urls: /datasets/laion-400m/webdataset-filtered/{00000..00010}.tar
        batch_size: 2
        shuffle: 1000
        partial: false
        decode: pil
        keep_only_keys:
        - jpg
        - txt
        transformations:
          jpg:
          - target: torchvision.transforms.ToTensor
          - target: torchvision.transforms.Resize
            params:
              size: 512
              interpolation: bicubic
          - target: torchvision.transforms.CenterCrop
            params:
              size: 512
        num_workers: 4
        persistent_workers: true
    validation:
      target: ldm.data.tsv.build_dataloader
      params:
        annotations_file: /datasets/coco2014/val2014_30k.tsv
        keys:
        - image_id
        - id
        - caption
        batch_size: 8
        shuffle: false
        num_workers: 1

Lightning config
trainer:
  accelerator: gpu
  num_nodes: 1
  devices: 8
  precision: 16
  logger: false
  log_every_n_steps: 5
  enable_progress_bar: false
  max_epochs: -1
  max_steps: 10000000000000
  val_check_interval: 1000
  enable_checkpointing: true
  num_sanity_val_steps: 0
  strategy:
    target: strategies.DDPStrategy
    params:
      find_unused_parameters: false
modelcheckpoint:
  target: lightning.pytorch.callbacks.ModelCheckpoint
  params:
    save_top_k: -1
    every_n_train_steps: 1000

:::MLLOG {"namespace": "", "time_ms": 1726447704853, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 90}}

  | Name              | Type                   | Params
-------------------------------------------------------------
0 | model             | DiffusionWrapper       | 865 M 
1 | first_stage_model | AutoencoderKL          | 83.7 M
2 | cond_stage_model  | FrozenOpenCLIPEmbedder | 354 M 
-------------------------------------------------------------
865 M     Trainable params
437 M     Non-trainable params
1.3 B     Total params
2,607.194 Total estimated model params size (MB)
/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loggers/tensorboard.py:188: UserWarning: Could not log computational graph to TensorBoard: The `model.example_input_array` attribute is not set or `input_array` was not given.
  rank_zero_warn(
/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training is starting
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
:::MLLOG {"namespace": "", "time_ms": 1726447706402, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 110, "samples_count": 0}}
/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/data.py:84: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:232: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.
  warning_cache.warn(
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
:::MLLOG {"namespace": "", "time_ms": 1726447761400, "event_type": "POINT_IN_TIME", "key": "loss", "value": 1.0289008617401123, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 120, "samples_count": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1726447761401, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 1.9800180199999997e-07, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 121, "samples_count": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1726447761401, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 122, "samples_count": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1726447761410, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 110, "samples_count": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1726447814425, "event_type": "POINT_IN_TIME", "key": "loss", "value": 1.0269830226898193, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 120, "samples_count": 3200}}
:::MLLOG {"namespace": "", "time_ms": 1726447814426, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 3.980016019999999e-07, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 121, "samples_count": 3200}}
:::MLLOG {"namespace": "", "time_ms": 1726447814426, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 122, "samples_count": 3200}}
:::MLLOG {"namespace": "", "time_ms": 1726447814435, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 110, "samples_count": 3200}}
:::MLLOG {"namespace": "", "time_ms": 1726447867628, "event_type": "POINT_IN_TIME", "key": "loss", "value": 0.897011399269104, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 120, "samples_count": 4800}}
:::MLLOG {"namespace": "", "time_ms": 1726447867628, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 5.980014019999998e-07, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 121, "samples_count": 4800}}
:::MLLOG {"namespace": "", "time_ms": 1726447867629, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 122, "samples_count": 4800}}
:::MLLOG {"namespace": "", "time_ms": 1726447867637, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 110, "samples_count": 4800}}
:::MLLOG {"namespace": "", "time_ms": 1726447920681, "event_type": "POINT_IN_TIME", "key": "loss", "value": 1.007652997970581, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 120, "samples_count": 6400}}
:::MLLOG {"namespace": "", "time_ms": 1726447920682, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 7.980012019999998e-07, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 121, "samples_count": 6400}}
:::MLLOG {"namespace": "", "time_ms": 1726447920682, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 122, "samples_count": 6400}}
:::MLLOG {"namespace": "", "time_ms": 1726447920692, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 110, "samples_count": 6400}}
:::MLLOG {"namespace": "", "time_ms": 1726447974444, "event_type": "POINT_IN_TIME", "key": "loss", "value": 0.8146206736564636, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 120, "samples_count": 8000}}
:::MLLOG {"namespace": "", "time_ms": 1726447974445, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 9.980010019999998e-07, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 121, "samples_count": 8000}}
:::MLLOG {"namespace": "", "time_ms": 1726447974445, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 122, "samples_count": 8000}}
:::MLLOG {"namespace": "", "time_ms": 1726447974453, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 110, "samples_count": 8000}}
:::MLLOG {"namespace": "", "time_ms": 1726448027481, "event_type": "POINT_IN_TIME", "key": "loss", "value": 0.8607375025749207, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 120, "samples_count": 9600}}
:::MLLOG {"namespace": "", "time_ms": 1726448027482, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 1.198000802e-06, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 121, "samples_count": 9600}}
:::MLLOG {"namespace": "", "time_ms": 1726448027482, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 122, "samples_count": 9600}}
:::MLLOG {"namespace": "", "time_ms": 1726448027491, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 110, "samples_count": 9600}}
:::MLLOG {"namespace": "", "time_ms": 1726448080468, "event_type": "POINT_IN_TIME", "key": "loss", "value": 0.6416677236557007, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 120, "samples_count": 11200}}
:::MLLOG {"namespace": "", "time_ms": 1726448080469, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 1.3980006019999999e-06, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 121, "samples_count": 11200}}
:::MLLOG {"namespace": "", "time_ms": 1726448080469, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 122, "samples_count": 11200}}
:::MLLOG {"namespace": "", "time_ms": 1726448080478, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 110, "samples_count": 11200}}
:::MLLOG {"namespace": "", "time_ms": 1726448133550, "event_type": "POINT_IN_TIME", "key": "loss", "value": 0.6338724493980408, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 120, "samples_count": 12800}}
:::MLLOG {"namespace": "", "time_ms": 1726448133551, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 1.5980004019999998e-06, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 121, "samples_count": 12800}}
:::MLLOG {"namespace": "", "time_ms": 1726448133551, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 122, "samples_count": 12800}}
:::MLLOG {"namespace": "", "time_ms": 1726448133559, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 110, "samples_count": 12800}}
:::MLLOG {"namespace": "", "time_ms": 1726448186665, "event_type": "POINT_IN_TIME", "key": "loss", "value": 0.6166895031929016, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 120, "samples_count": 14400}}
:::MLLOG {"namespace": "", "time_ms": 1726448186666, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 1.7980002019999999e-06, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 121, "samples_count": 14400}}
:::MLLOG {"namespace": "", "time_ms": 1726448186666, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 122, "samples_count": 14400}}
:::MLLOG {"namespace": "", "time_ms": 1726448186674, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 110, "samples_count": 14400}}
:::MLLOG {"namespace": "", "time_ms": 1726448239631, "event_type": "POINT_IN_TIME", "key": "loss", "value": 0.5953646302223206, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 120, "samples_count": 16000}}
:::MLLOG {"namespace": "", "time_ms": 1726448239632, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 1.998000002e-06, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 121, "samples_count": 16000}}
:::MLLOG {"namespace": "", "time_ms": 1726448239632, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 122, "samples_count": 16000}}
:::MLLOG {"namespace": "", "time_ms": 1726448292633, "event_type": "INTERVAL_START", "key": "eval_start", "value": 16000, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 125, "samples_count": 16000}}
:::MLLOG {"namespace": "", "time_ms": 1726448292782, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 64}}
:::MLLOG {"namespace": "", "time_ms": 1726448333810, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 64}}
:::MLLOG {"namespace": "", "time_ms": 1726448487625, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 704}}
:::MLLOG {"namespace": "", "time_ms": 1726448504829, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 704}}
:::MLLOG {"namespace": "", "time_ms": 1726448659212, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 1344}}
:::MLLOG {"namespace": "", "time_ms": 1726448676358, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 1344}}
:::MLLOG {"namespace": "", "time_ms": 1726448830916, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 1984}}
:::MLLOG {"namespace": "", "time_ms": 1726448848191, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 1984}}
:::MLLOG {"namespace": "", "time_ms": 1726449003058, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 2624}}
:::MLLOG {"namespace": "", "time_ms": 1726449020080, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 2624}}
:::MLLOG {"namespace": "", "time_ms": 1726449176168, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 3264}}
:::MLLOG {"namespace": "", "time_ms": 1726449193319, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 3264}}
:::MLLOG {"namespace": "", "time_ms": 1726449348970, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 3904}}
:::MLLOG {"namespace": "", "time_ms": 1726449366202, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 3904}}
:::MLLOG {"namespace": "", "time_ms": 1726449522843, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 4544}}
:::MLLOG {"namespace": "", "time_ms": 1726449539851, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 4544}}
:::MLLOG {"namespace": "", "time_ms": 1726449696309, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 5184}}
:::MLLOG {"namespace": "", "time_ms": 1726449713435, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 5184}}
:::MLLOG {"namespace": "", "time_ms": 1726449869475, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 5824}}
:::MLLOG {"namespace": "", "time_ms": 1726449886621, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 5824}}
:::MLLOG {"namespace": "", "time_ms": 1726450043472, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 6464}}
:::MLLOG {"namespace": "", "time_ms": 1726450060518, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 6464}}
:::MLLOG {"namespace": "", "time_ms": 1726450217778, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 7104}}
:::MLLOG {"namespace": "", "time_ms": 1726450234911, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 7104}}
:::MLLOG {"namespace": "", "time_ms": 1726450391697, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 7744}}
:::MLLOG {"namespace": "", "time_ms": 1726450408777, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 7744}}
:::MLLOG {"namespace": "", "time_ms": 1726450565679, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 8384}}
:::MLLOG {"namespace": "", "time_ms": 1726450582825, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 8384}}
:::MLLOG {"namespace": "", "time_ms": 1726450739614, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 9024}}
:::MLLOG {"namespace": "", "time_ms": 1726450756926, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 9024}}
:::MLLOG {"namespace": "", "time_ms": 1726450913715, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 9664}}
:::MLLOG {"namespace": "", "time_ms": 1726450930858, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 9664}}
:::MLLOG {"namespace": "", "time_ms": 1726451087631, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 10304}}
:::MLLOG {"namespace": "", "time_ms": 1726451104890, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 10304}}
:::MLLOG {"namespace": "", "time_ms": 1726451261961, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 10944}}
:::MLLOG {"namespace": "", "time_ms": 1726451279058, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 10944}}
:::MLLOG {"namespace": "", "time_ms": 1726451436032, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 11584}}
:::MLLOG {"namespace": "", "time_ms": 1726451453193, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 11584}}
:::MLLOG {"namespace": "", "time_ms": 1726451610991, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 12224}}
:::MLLOG {"namespace": "", "time_ms": 1726451628052, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 12224}}
:::MLLOG {"namespace": "", "time_ms": 1726451785406, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 12864}}
:::MLLOG {"namespace": "", "time_ms": 1726451802509, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 12864}}
:::MLLOG {"namespace": "", "time_ms": 1726451960026, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 13504}}
:::MLLOG {"namespace": "", "time_ms": 1726451977214, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 13504}}
:::MLLOG {"namespace": "", "time_ms": 1726452134776, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 14144}}
:::MLLOG {"namespace": "", "time_ms": 1726452152105, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 14144}}
:::MLLOG {"namespace": "", "time_ms": 1726452309761, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 14784}}
:::MLLOG {"namespace": "", "time_ms": 1726452327030, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 14784}}
:::MLLOG {"namespace": "", "time_ms": 1726452484358, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 15424}}
:::MLLOG {"namespace": "", "time_ms": 1726452501400, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 15424}}
:::MLLOG {"namespace": "", "time_ms": 1726452659447, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 16064}}
:::MLLOG {"namespace": "", "time_ms": 1726452676690, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 16064}}
:::MLLOG {"namespace": "", "time_ms": 1726452834686, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 16704}}
:::MLLOG {"namespace": "", "time_ms": 1726452851735, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 16704}}
:::MLLOG {"namespace": "", "time_ms": 1726453009900, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 17344}}
:::MLLOG {"namespace": "", "time_ms": 1726453027157, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 17344}}
:::MLLOG {"namespace": "", "time_ms": 1726453184937, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 17984}}
:::MLLOG {"namespace": "", "time_ms": 1726453202232, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 17984}}
:::MLLOG {"namespace": "", "time_ms": 1726453360345, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 18624}}
:::MLLOG {"namespace": "", "time_ms": 1726453377522, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 18624}}
:::MLLOG {"namespace": "", "time_ms": 1726453535805, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 19264}}
:::MLLOG {"namespace": "", "time_ms": 1726453552933, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 19264}}
:::MLLOG {"namespace": "", "time_ms": 1726453711887, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 19904}}
:::MLLOG {"namespace": "", "time_ms": 1726453729166, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 19904}}
:::MLLOG {"namespace": "", "time_ms": 1726453886760, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 20544}}
:::MLLOG {"namespace": "", "time_ms": 1726453903748, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 20544}}
:::MLLOG {"namespace": "", "time_ms": 1726454062319, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 21184}}
:::MLLOG {"namespace": "", "time_ms": 1726454079352, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 21184}}
:::MLLOG {"namespace": "", "time_ms": 1726454237158, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 21824}}
:::MLLOG {"namespace": "", "time_ms": 1726454254227, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 21824}}
:::MLLOG {"namespace": "", "time_ms": 1726454412776, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 22464}}
:::MLLOG {"namespace": "", "time_ms": 1726454429859, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 22464}}
:::MLLOG {"namespace": "", "time_ms": 1726454588306, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 23104}}
:::MLLOG {"namespace": "", "time_ms": 1726454605583, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 23104}}
:::MLLOG {"namespace": "", "time_ms": 1726454764269, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 23744}}
:::MLLOG {"namespace": "", "time_ms": 1726454781408, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 23744}}
:::MLLOG {"namespace": "", "time_ms": 1726454939301, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 24384}}
:::MLLOG {"namespace": "", "time_ms": 1726454956342, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 24384}}
:::MLLOG {"namespace": "", "time_ms": 1726455115068, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 25024}}
:::MLLOG {"namespace": "", "time_ms": 1726455132102, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 25024}}
:::MLLOG {"namespace": "", "time_ms": 1726455290305, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 151, "samples_count": 25664}}
:::MLLOG {"namespace": "", "time_ms": 1726455307465, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 156, "samples_count": 25664}}
